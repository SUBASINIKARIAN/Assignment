{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Lookalike Model Development\n",
        "\n",
        "## Importing Libraries\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.preprocessing import OneHotEncoder\n",
        "\n",
        "## Loading Data\n",
        "customers = pd.read_csv('/Volumes/DATA/Assignment/Data/Customers - Customers.csv')\n",
        "products = pd.read_csv('/Volumes/DATA/Assignment/Data/Products - Products.csv')\n",
        "transactions = pd.read_csv('/Volumes/DATA/Assignment/Data/Transactions - Transactions.csv')\n",
        "\n",
        "## Merging Datasets\n",
        "merged_data = pd.merge(transactions, customers, on='CustomerID', how='inner')\n",
        "merged_data = pd.merge(merged_data, products, on='ProductID', how='inner')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "Index(['TransactionID', 'CustomerID', 'ProductID', 'TransactionDate',\n",
              "       'Quantity', 'TotalValue', 'Price_x', 'CustomerName', 'Region',\n",
              "       'SignupDate', 'ProductName', 'Category', 'Price_y'],\n",
              "      dtype='object')"
            ]
          },
          "execution_count": 3,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "merged_data.columns"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Shape of features array: (199, 10)\n",
            "LookalikeRecommendations.xlsx has been created with different similarity metrics.\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from datetime import datetime\n",
        "\n",
        "# Load merged data\n",
        "data = merged_data\n",
        "\n",
        "# Feature Engineering\n",
        "# Calculate days since signup\n",
        "data['SignupDate'] = pd.to_datetime(data['SignupDate'])\n",
        "data['DaysSinceSignup'] = (datetime.now() - data['SignupDate']).dt.days\n",
        "\n",
        "# Aggregate features per customer\n",
        "customer_features = data.groupby(\"CustomerID\").agg({\n",
        "    'Region': 'first',  # Region stays the same for a customer\n",
        "    'TotalValue': 'mean',  # Average transaction value\n",
        "    'Quantity': 'sum',  # Total quantity purchased\n",
        "    'Category': lambda x: x.mode()[0],  # Most frequent product category\n",
        "    'Price_y': 'mean',  # Average product price\n",
        "    'DaysSinceSignup': 'first'  # Days since signup\n",
        "}).reset_index()\n",
        "\n",
        "# One-hot encode categorical features (Region and Category)\n",
        "customer_features = pd.get_dummies(customer_features, columns=['Region', 'Category'], drop_first=True)\n",
        "\n",
        "# Normalize numerical features\n",
        "scaler = StandardScaler()\n",
        "numerical_cols = ['TotalValue', 'Quantity', 'Price_y', 'DaysSinceSignup']\n",
        "customer_features[numerical_cols] = scaler.fit_transform(customer_features[numerical_cols])\n",
        "\n",
        "# Similarity Computation\n",
        "customer_ids = customer_features['CustomerID']\n",
        "features = customer_features.drop(columns=['CustomerID']).values\n",
        "similarity_matrix = cosine_similarity(features)\n",
        "\n",
        "# Generate Lookalike Recommendations\n",
        "lookalike_map = {}\n",
        "\n",
        "for i, cust_id in enumerate(customer_ids[:20]):  # First 20 customers\n",
        "    scores = list(enumerate(similarity_matrix[i]))\n",
        "    # Sort by similarity score in descending order, ignoring self-comparison\n",
        "    sorted_scores = sorted(scores, key=lambda x: x[1], reverse=True)[1:4]\n",
        "    lookalike_map[cust_id] = [(customer_ids[j], round(score, 4)) for j, score in sorted_scores]\n",
        "\n",
        "# Save Lookalike.csv\n",
        "lookalike_df = pd.DataFrame([\n",
        "    {\"CustomerID\": cust_id, \"Lookalikes\": lookalikes}\n",
        "    for cust_id, lookalikes in lookalike_map.items()\n",
        "])\n",
        "lookalike_df.to_csv(\"Subasini_K_Lookalike.csv\", index=False)\n",
        "\n",
        "print(\"Lookalike.csv has been created.\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.4"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 4
}
